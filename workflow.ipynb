{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\http\\client.py:1395\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1394\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1395\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1396\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\http\\client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\http\\client.py:286\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\socket.py:718\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m718\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\ssl.py:1314\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1311\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1312\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1313\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\ssl.py:1166\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mTimeoutError\u001b[39m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mReadTimeoutError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\urllib3\\util\\retry.py:474\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_method_retryable(method):\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\urllib3\\util\\util.py:39\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n\u001b[32m     38\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\urllib3\\connectionpool.py:367\u001b[39m, in \u001b[36mHTTPConnectionPool._raise_timeout\u001b[39m\u001b[34m(self, err, url, timeout_value)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m, url, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    369\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[31mReadTimeoutError\u001b[39m: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\IPython\\core\\formatters.py:1036\u001b[39m, in \u001b[36mMimeBundleFormatter.__call__\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n\u001b[32m   1033\u001b[39m     method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n\u001b[32m   1035\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langgraph\\graph\\graph.py:641\u001b[39m, in \u001b[36mCompiledGraph._repr_mimebundle_\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_repr_mimebundle_\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    638\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Mime bundle used by Jupyter to display the graph\"\"\"\u001b[39;00m\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    640\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtext/plain\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m),\n\u001b[32m--> \u001b[39m\u001b[32m641\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimage/png\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    642\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langchain_core\\runnables\\graph.py:631\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding)\u001b[39m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[32m    626\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    627\u001b[39m     curve_style=curve_style,\n\u001b[32m    628\u001b[39m     node_colors=node_colors,\n\u001b[32m    629\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    630\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m631\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:215\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding)\u001b[39m\n\u001b[32m    209\u001b[39m     img_bytes = asyncio.run(\n\u001b[32m    210\u001b[39m         _render_mermaid_using_pyppeteer(\n\u001b[32m    211\u001b[39m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[32m    212\u001b[39m         )\n\u001b[32m    213\u001b[39m     )\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     img_bytes = \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_color\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    219\u001b[39m     supported_methods = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([m.value \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:333\u001b[39m, in \u001b[36m_render_mermaid_using_api\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, file_type)\u001b[39m\n\u001b[32m    327\u001b[39m         background_color = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m!\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackground_color\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    329\u001b[39m image_url = (\n\u001b[32m    330\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://mermaid.ink/img/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmermaid_syntax_encoded\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    331\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m?type=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m&bgColor=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackground_color\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    332\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m:\n\u001b[32m    335\u001b[39m     img_bytes = response.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\requests\\adapters.py:713\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m    712\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[32m--> \u001b[39m\u001b[32m713\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request=request)\n\u001b[32m    714\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[32m    715\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request=request)\n",
      "\u001b[31mReadTimeout\u001b[39m: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph at 0x1ecba07fdd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph,START,MessagesState,END\n",
    "from typing import TypedDict, Literal, Optional\n",
    "\n",
    "# Define the workflow state class\n",
    "class WorkflowState(TypedDict):\n",
    "    phase: Literal[\n",
    "        \"Requirements\", \"User Stories\", \"Design\", \"Development\", \n",
    "        \"Code Review\", \"Security Review\", \"Testing\", \"Deployment\", \n",
    "        \"Monitoring\", \"Maintenance\"\n",
    "    ]\n",
    "    approval_status: Literal[\"Pending\", \"Approved\", \"Needs Revision\"]\n",
    "    feedback: Optional[str]\n",
    "    code_status: Literal[\"Not Started\", \"In Progress\", \"Completed\"]\n",
    "    test_status: Literal[\"Not Started\", \"In Progress\", \"Completed\"]\n",
    "    deployment_status: Literal[\"Not Started\", \"In Progress\", \"Completed\"]\n",
    "    monitoring_status: Literal[\"Not Started\", \"In Progress\", \"Completed\"]\n",
    "\n",
    "# Initialize the LangGraph workflow\n",
    "graph = StateGraph(WorkflowState)\n",
    "\n",
    "def generate_user_stories(MessagesState):\n",
    "    ...\n",
    "\n",
    "def product_owner_review(MessagesState):\n",
    "    ...\n",
    "\n",
    "def create_design_document(MessagesState):\n",
    "    ...\n",
    "\n",
    "\n",
    "def revise_user_stories(MessagesState):\n",
    "    ...\n",
    "\n",
    "def product_owner_status(MessagesState):\n",
    "    return \"Approved\"\n",
    "\n",
    "def design_review(MessagesState):\n",
    "    ...\n",
    "\n",
    "def validate_design_review(MessagesState):\n",
    "    return \"Approved\"\n",
    "\n",
    "def generate_code(MessagesState):\n",
    "    return \"Approved\"\n",
    "\n",
    "\n",
    "graph.add_node(\"user_stories\",generate_user_stories)\n",
    "graph.add_node(\"owner_review\",product_owner_review)\n",
    "graph.add_node(\"new_design_document\",create_design_document)\n",
    "graph.add_node(\"revise_stories\",revise_user_stories)\n",
    "graph.add_node(\"review_design\",design_review)\n",
    "graph.add_node(\"code_generation\",generate_code)\n",
    "\n",
    "\n",
    "graph.add_edge(START,\"user_stories\")\n",
    "graph.add_edge(\"user_stories\",\"owner_review\")\n",
    "graph.add_conditional_edges(\"owner_review\",product_owner_status,{\"Approved\":\"new_design_document\",\"Feedback\":\"revise_stories\"})\n",
    "graph.add_edge(\"new_design_document\",\"review_design\")\n",
    "graph.add_edge(\"revise_stories\",\"user_stories\")\n",
    "graph.add_conditional_edges(\"review_design\",validate_design_review,{\"Approved\":\"code_generation\",\"Feedback\":\"new_design_document\"})\n",
    "graph.add_edge(\"code_generation\",END)\n",
    "\n",
    "graph.compile()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': 'The model `text-davinci-003` has been deprecated, learn more here: https://platform.openai.com/docs/deprecations', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     65\u001b[39m user_stories = [\n\u001b[32m     66\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAs a user, I want to register with my email and password so that I can create an account.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     67\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAs a user, I want to log in using my email and password so that I can access my account.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     68\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAs an admin, I want to view a list of registered users so that I can manage accounts.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     69\u001b[39m ]\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# Generate the comprehensive specification document\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m comprehensive_spec = \u001b[43mgenerate_comprehensive_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_stories\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mComprehensive Specification Document:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, comprehensive_spec)\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Save the document to a DOCX file\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mgenerate_comprehensive_spec\u001b[39m\u001b[34m(user_stories)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# # Call the OpenAI API to generate the document\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# response = openai.Completion.create(\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m#     model=\"text-davinci-003\",  # Or use \"gpt-4\" if you have access\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m \u001b[38;5;66;03m#     temperature=0.7\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m     58\u001b[39m llm = ChatOpenAI(model=\u001b[33m\"\u001b[39m\u001b[33mtext-davinci-003\u001b[39m\u001b[33m\"\u001b[39m,stream_usage=\u001b[38;5;28;01mTrue\u001b[39;00m,api_key=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Return the generated text (the document content)\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].text.strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:285\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    275\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    276\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    280\u001b[39m     **kwargs: Any,\n\u001b[32m    281\u001b[39m ) -> BaseMessage:\n\u001b[32m    282\u001b[39m     config = ensure_config(config)\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    284\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    295\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:861\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    853\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    854\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    855\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    858\u001b[39m     **kwargs: Any,\n\u001b[32m    859\u001b[39m ) -> LLMResult:\n\u001b[32m    860\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:691\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    689\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    690\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m691\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m         )\n\u001b[32m    698\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    699\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:926\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    930\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:800\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    798\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m    799\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:879\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    837\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    839\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    876\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    877\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    878\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    913\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    914\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\openai\\_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\openai\\_base_client.py:919\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    917\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\openai\\_base_client.py:1023\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1020\u001b[39m         err.response.read()\n\u001b[32m   1022\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1026\u001b[39m     cast_to=cast_to,\n\u001b[32m   1027\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1031\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1032\u001b[39m )\n",
      "\u001b[31mNotFoundError\u001b[39m: Error code: 404 - {'error': {'message': 'The model `text-davinci-003` has been deprecated, learn more here: https://platform.openai.com/docs/deprecations', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import openai\n",
    "from docx import Document\n",
    "\n",
    "# Set up OpenAI API key\n",
    "openai.api_key = ''  # Use your OpenAI API key here\n",
    "combined_spec_prompt = \"\"\"\n",
    "You are an AI that generates a comprehensive software system specification document. Based on the following user stories, create a single document that includes both functional and design specifications.\n",
    "\n",
    "### User Stories\n",
    "{user_stories}\n",
    "\n",
    "### Functional Specification\n",
    "\n",
    "Based on the above user stories, generate a functional specification document that includes:\n",
    "1. Functional Requirements\n",
    "2. Non-Functional Requirements\n",
    "3. Constraints\n",
    "4. Stakeholders\n",
    "\n",
    "### Design Specification\n",
    "\n",
    "Based on the system functionality described above, generate a design specification document that includes:\n",
    "1. Architecture Overview\n",
    "2. Data Model\n",
    "3. Components and their Interactions\n",
    "4. API Contracts\n",
    "5. Security Considerations\n",
    "\n",
    "Please structure the document as follows:\n",
    "1. Overview\n",
    "2. Functional Specifications\n",
    "3. Non-Functional Specifications\n",
    "4. Constraints\n",
    "5. Stakeholders\n",
    "6. Architecture Overview\n",
    "7. Data Model\n",
    "8. Components and Interactions\n",
    "9. API Contracts\n",
    "10. Security Considerations\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Function to generate the comprehensive document (functional and design)\n",
    "def generate_comprehensive_spec(user_stories):\n",
    "    # Format the combined prompt\n",
    "    prompt = combined_spec_prompt.format(\n",
    "        user_stories=\"\\n\".join([f\"- {story}\" for story in user_stories])\n",
    "    )\n",
    "\n",
    "    # # Call the OpenAI API to generate the document\n",
    "    # response = openai.Completion.create(\n",
    "    #     model=\"text-davinci-003\",  # Or use \"gpt-4\" if you have access\n",
    "    #     prompt=prompt,\n",
    "    #     max_tokens=3000,\n",
    "    #     temperature=0.7\n",
    "    # )\n",
    "    llm = ChatOpenAI(model=\"text-davinci-003\",stream_usage=True,api_key=\"\")\n",
    "    response = llm.invoke(prompt)\n",
    "    # Return the generated text (the document content)\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "\n",
    "# Example User Stories\n",
    "user_stories = [\n",
    "    \"As a user, I want to register with my email and password so that I can create an account.\",\n",
    "    \"As a user, I want to log in using my email and password so that I can access my account.\",\n",
    "    \"As an admin, I want to view a list of registered users so that I can manage accounts.\"\n",
    "]\n",
    "\n",
    "# Generate the comprehensive specification document\n",
    "comprehensive_spec = generate_comprehensive_spec(user_stories)\n",
    "\n",
    "print(\"Comprehensive Specification Document:\\n\", comprehensive_spec)\n",
    "\n",
    "# Save the document to a DOCX file\n",
    "doc = Document()\n",
    "doc.add_heading('Comprehensive Specification Document for User Registration and Login', 0)\n",
    "\n",
    "# Add the generated content to the Word document\n",
    "doc.add_paragraph(comprehensive_spec)\n",
    "\n",
    "# Save the DOCX document\n",
    "doc.save('comprehensive_specification.docx')\n",
    "\n",
    "print(\"Comprehensive specification document saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the state\n",
    "from langgraph.graph import MessagesState, START\n",
    "\n",
    "# Set up the tool\n",
    "# We will have one real tool - a search tool\n",
    "# We'll also have one \"fake\" tool - a \"ask_human\" tool\n",
    "# Here we define any ACTUAL tools\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"Call to surf the web.\"\"\"\n",
    "    # This is a placeholder for the actual implementation\n",
    "    # Don't let the LLM know this though 😊\n",
    "    return f\"I looked up: {query}. Result: It's sunny in San Francisco, but you better look out if you're a Gemini 😈.\"\n",
    "\n",
    "\n",
    "tools = [search]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Set up the model\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\",stream_usage=True,api_key=\"\")\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# We are going \"bind\" all tools to the model\n",
    "# We have the ACTUAL tools from above, but we also need a mock tool to ask a human\n",
    "# Since `bind_tools` takes in tools but also just tool definitions,\n",
    "# We can define a tool definition for `ask_human`\n",
    "class AskHuman(BaseModel):\n",
    "    \"\"\"Ask the human a question\"\"\"\n",
    "\n",
    "    question: str\n",
    "\n",
    "\n",
    "model = model.bind_tools(tools + [AskHuman])\n",
    "\n",
    "# Define nodes and conditional edges\n",
    "\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return END\n",
    "    # If tool call is asking Human, we return that node\n",
    "    # You could also add logic here to let some system know that there's something that requires Human input\n",
    "    # For example, send a slack message, etc\n",
    "    elif last_message.tool_calls[0][\"name\"] == \"AskHuman\":\n",
    "        return \"ask_human\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"action\"\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# We define a fake node to ask the human\n",
    "def ask_human(state):\n",
    "    tool_call_id = state[\"messages\"][-1].tool_calls[0][\"id\"]\n",
    "    location = input(\"Please provide your location:\")\n",
    "    tool_message = [{\"tool_call_id\": tool_call_id, \"type\": \"tool\", \"content\": location}]\n",
    "    return {\"messages\": tool_message}\n",
    "\n",
    "\n",
    "# Build the graph\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the three nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", tool_node)\n",
    "workflow.add_node(\"ask_human\", ask_human)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "\n",
    "# After we get back the human response, we go back to the agent\n",
    "workflow.add_edge(\"ask_human\", \"agent\")\n",
    "\n",
    "# Set up memory\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "# We add a breakpoint BEFORE the `ask_human` node so it never executes\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "#display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001FDBEE82110>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Use the search tool to ask the user where they are, then look up the weather there\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  AskHuman (call_P4InR1rz0Y9hu1iC46hKIkaM)\n",
      " Call ID: call_P4InR1rz0Y9hu1iC46hKIkaM\n",
      "  Args:\n",
      "    question: Could you please provide a specific city or region in India for a more accurate weather update?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Bangalore\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search (call_Gx7jLEWnYaIqFnXVXf2qHG8f)\n",
      " Call ID: call_Gx7jLEWnYaIqFnXVXf2qHG8f\n",
      "  Args:\n",
      "    query: current weather in Bangalore\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search\n",
      "\n",
      "I looked up: current weather in Bangalore. Result: It's sunny in San Francisco, but you better look out if you're a Gemini 😈.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Unfortunately, I encountered an error retrieving the weather information for Bangalore. You might want to check a local weather website or app for the latest conditions. If you have any other questions or need assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in app.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Use the search tool to ask the user where they are, then look up the weather there\",\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001FDBEE2B090>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import MessagesState, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"Call to surf the web.\"\"\"\n",
    "    # This is a placeholder for the actual implementation\n",
    "    # Don't let the LLM know this though 😊\n",
    "    return [\n",
    "        \"It's sunny in San Francisco, but you better look out if you're a Gemini 😈.\"\n",
    "    ]\n",
    "\n",
    "\n",
    "tools = [search]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Set up the model\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\",stream_usage=True,api_key=\"\")\n",
    "model = model.bind_tools(tools)\n",
    "\n",
    "\n",
    "# Define nodes and conditional edges\n",
    "\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"action\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "\n",
    "# Set up memory\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "\n",
    "# We add in `interrupt_before=[\"action\"]`\n",
    "# This will add a breakpoint before the `action` node is called\n",
    "app = workflow.compile(checkpointer=memory, interrupt_before=[\"action\"])\n",
    "\n",
    "#display(Image(app.get_graph().draw_mermaid_png()))\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "search for the weather in sf now\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_zb1eyn8GZeTkxuvi3CVtxExf\", 'type': 'invalid_request_error', 'param': 'messages.[2].role', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m thread = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m3\u001b[39m\u001b[33m\"\u001b[39m}}\n\u001b[32m      4\u001b[39m inputs = [HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33msearch for the weather in sf now\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2024\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   2018\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2019\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2020\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2021\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2022\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2023\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2025\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2026\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2027\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2028\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2029\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2030\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2031\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2032\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langgraph\\pregel\\runner.py:230\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    228\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langgraph\\utils\\runnable.py:546\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    542\u001b[39m config = patch_config(\n\u001b[32m    543\u001b[39m     config, callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    544\u001b[39m )\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m546\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    548\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langgraph\\utils\\runnable.py:310\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    309\u001b[39m     context.run(_set_config_context, config)\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mcall_model\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_model\u001b[39m(state):\n\u001b[32m     46\u001b[39m     messages = state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# We return a list, because this will get added to the existing list\u001b[39;00m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [response]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5365\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5359\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5360\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5361\u001b[39m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[32m   5362\u001b[39m     config: Optional[RunnableConfig] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5363\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5364\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5366\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5367\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5368\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5369\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:285\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    275\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    276\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    280\u001b[39m     **kwargs: Any,\n\u001b[32m    281\u001b[39m ) -> BaseMessage:\n\u001b[32m    282\u001b[39m     config = ensure_config(config)\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    284\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    295\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:861\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    853\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    854\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    855\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    858\u001b[39m     **kwargs: Any,\n\u001b[32m    859\u001b[39m ) -> LLMResult:\n\u001b[32m    860\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:691\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    689\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    690\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m691\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m         )\n\u001b[32m    698\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    699\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:926\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    930\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:800\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    798\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m    799\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:879\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    837\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    839\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    876\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    877\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    878\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    913\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    914\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\openai\\_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\openai\\_base_client.py:919\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    917\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\openai\\_base_client.py:1023\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1020\u001b[39m         err.response.read()\n\u001b[32m   1022\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1026\u001b[39m     cast_to=cast_to,\n\u001b[32m   1027\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1031\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1032\u001b[39m )\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_zb1eyn8GZeTkxuvi3CVtxExf\", 'type': 'invalid_request_error', 'param': 'messages.[2].role', 'code': None}}",
      "During task with name 'agent' and id '4ca23563-3667-50ee-3272-294e0d4abd8c'"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "inputs = [HumanMessage(content=\"search for the weather in sf now\")]\n",
    "for event in app.stream({\"messages\": inputs}, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'dict' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     60\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m state  \u001b[38;5;66;03m# Continue to AI Review\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Step 8: Compile Workflow with `interrupt_before`\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m app = \u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mproduct_owner_review\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhuman_review_interrupt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Step 9: Execute Streaming with `app.stream()`\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🚀 Streaming Execution Started...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AgenticAI\\Hackathon\\Hackathon\\Lib\\site-packages\\langgraph\\graph\\state.py:541\u001b[39m, in \u001b[36mStateGraph.compile\u001b[39m\u001b[34m(self, checkpointer, store, interrupt_before, interrupt_after, debug, name)\u001b[39m\n\u001b[32m    536\u001b[39m interrupt_after = interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    538\u001b[39m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[32m    539\u001b[39m \u001b[38;5;28mself\u001b[39m.validate(\n\u001b[32m    540\u001b[39m     interrupt=(\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m         \u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[32m    542\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m interrupt_after != \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    543\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m    544\u001b[39m     )\n\u001b[32m    545\u001b[39m )\n\u001b[32m    547\u001b[39m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[32m    548\u001b[39m output_channels = (\n\u001b[32m    549\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m__root__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    550\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.schemas[\u001b[38;5;28mself\u001b[39m.output]) == \u001b[32m1\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    556\u001b[39m     ]\n\u001b[32m    557\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for +: 'dict' and 'list'"
     ]
    }
   ],
   "source": [
    "import langgraph\n",
    "import threading\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from typing import TypedDict, Literal\n",
    "\n",
    "# Initialize OpenAI Model\n",
    "llm = ChatOpenAI(model_name=\"gpt-4-turbo\",api_key=\"\")\n",
    "\n",
    "# Step 1: Define Workflow State\n",
    "class ReviewState(TypedDict):\n",
    "    status: Literal[\"Pending Review\", \"Approved\", \"Rejected\", \"Needs Human Input\"]\n",
    "    request_data: str\n",
    "\n",
    "# Step 2: Create StateGraph using langgraph.graph.StateGraph\n",
    "workflow = StateGraph(ReviewState)\n",
    "\n",
    "# Step 3: Developer Submits a Request\n",
    "def submit_request(state: ReviewState) -> ReviewState:\n",
    "    return {\"status\": \"Pending Review\", \"request_data\": state[\"request_data\"]}\n",
    "\n",
    "workflow.add_node(\"submit_request\", submit_request)\n",
    "\n",
    "# Step 4: AI-Based Product Owner Review\n",
    "def product_owner_review(state: ReviewState) -> ReviewState:\n",
    "    \"\"\"Automated AI review\"\"\"\n",
    "    review_prompt = f\"Review request: {state['request_data']}. Approve or Reject?\"\n",
    "    response = llm([HumanMessage(content=review_prompt)])\n",
    "\n",
    "    if \"approve\" in response.content.lower():\n",
    "        return {\"status\": \"Approved\", \"request_data\": state[\"request_data\"]}\n",
    "    elif \"reject\" in response.content.lower():\n",
    "        return {\"status\": \"Rejected\", \"request_data\": state[\"request_data\"]}\n",
    "    else:\n",
    "        return {\"status\": \"Needs Human Input\", \"request_data\": state[\"request_data\"]}\n",
    "\n",
    "workflow.add_node(\"product_owner_review\", product_owner_review)\n",
    "\n",
    "# Step 5: Final Decision Node\n",
    "def final_decision(state: ReviewState) -> ReviewState:\n",
    "    \"\"\"Store the final decision\"\"\"\n",
    "    return {\"status\": state[\"status\"], \"request_data\": state[\"request_data\"]}\n",
    "\n",
    "workflow.add_node(\"final_decision\", final_decision)\n",
    "\n",
    "# Step 6: Define Workflow Execution Paths\n",
    "workflow.add_edge(\"submit_request\", \"product_owner_review\")\n",
    "workflow.add_edge(\"product_owner_review\", \"final_decision\")\n",
    "\n",
    "# Step 7: Human Interrupt Before AI Review\n",
    "def human_review_interrupt(state: ReviewState) -> ReviewState:\n",
    "    \"\"\"Pause execution before AI review for human input.\"\"\"\n",
    "    print(\"\\n⏸️ Execution Paused! Human Review Needed.\")\n",
    "    human_decision = input(\"Enter decision (Approve/Reject/Continue to AI): \").strip().lower()\n",
    "\n",
    "    if human_decision in [\"approve\", \"reject\"]:\n",
    "        return {\"status\": human_decision, \"request_data\": state[\"request_data\"]}  # Skip AI\n",
    "    else:\n",
    "        return state  # Continue to AI Review\n",
    "\n",
    "# Step 8: Compile Workflow with `interrupt_before`\n",
    "app = workflow.compile(interrupt_before={\"product_owner_review\": human_review_interrupt})\n",
    "\n",
    "# Step 9: Execute Streaming with `app.stream()`\n",
    "print(\"\\n🚀 Streaming Execution Started...\\n\")\n",
    "\n",
    "# Run the streaming process in a separate thread\n",
    "thread = threading.Thread(target=lambda: app.stream(None, thread, stream_mode=\"values\"))\n",
    "thread.start()\n",
    "\n",
    "# Process streaming output\n",
    "for event in app.stream(None, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "print(\"\\n✅ Final Decision Reached!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Streaming Execution Started...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26780\\2523781708.py:29: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm([HumanMessage(content=review_prompt)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final Decision Reached!\n"
     ]
    }
   ],
   "source": [
    "import langgraph\n",
    "import threading\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from typing import TypedDict, Literal\n",
    "\n",
    "# Initialize OpenAI Model\n",
    "llm = ChatOpenAI(model_name=\"gpt-4-turbo\",api_key=\"\")\n",
    "\n",
    "# Step 1: Define Workflow State\n",
    "class ReviewState(TypedDict):\n",
    "    status: Literal[\"Pending Review\", \"Approved\", \"Rejected\", \"Needs Human Input\"]\n",
    "    request_data: str\n",
    "\n",
    "# Step 2: Create StateGraph using langgraph.graph.StateGraph\n",
    "workflow = StateGraph(ReviewState)\n",
    "\n",
    "# Step 3: Developer Submits a Request\n",
    "def submit_request(state: ReviewState) -> ReviewState:\n",
    "    return {\"status\": \"Pending Review\", \"request_data\": state[\"request_data\"]}\n",
    "\n",
    "workflow.add_node(\"submit_request\", submit_request)\n",
    "\n",
    "# Step 4: AI-Based Product Owner Review\n",
    "def product_owner_review(state: ReviewState) -> ReviewState:\n",
    "    \"\"\"Automated AI review\"\"\"\n",
    "    review_prompt = f\"Review request: {state['request_data']}. Approve or Reject?\"\n",
    "    response = llm([HumanMessage(content=review_prompt)])\n",
    "\n",
    "    if \"approve\" in response.content.lower():\n",
    "        return {\"status\": \"Approved\", \"request_data\": state[\"request_data\"]}\n",
    "    elif \"reject\" in response.content.lower():\n",
    "        return {\"status\": \"Rejected\", \"request_data\": state[\"request_data\"]}\n",
    "    else:\n",
    "        return {\"status\": \"Needs Human Input\", \"request_data\": state[\"request_data\"]}\n",
    "\n",
    "workflow.add_node(\"product_owner_review\", product_owner_review)\n",
    "\n",
    "# Step 5: Final Decision Node\n",
    "def final_decision(state: ReviewState) -> ReviewState:\n",
    "    \"\"\"Store the final decision\"\"\"\n",
    "    return {\"status\": state[\"status\"], \"request_data\": state[\"request_data\"]}\n",
    "\n",
    "workflow.add_node(\"final_decision\", final_decision)\n",
    "\n",
    "# Step 6: Define Workflow Execution Paths\n",
    "workflow.set_entry_point(\"submit_request\")\n",
    "workflow.add_edge(\"submit_request\", \"product_owner_review\")\n",
    "workflow.add_edge(\"product_owner_review\", \"final_decision\")\n",
    "\n",
    "# Step 7: Human Interrupt Before AI Review\n",
    "def human_review_interrupt(state: ReviewState) -> ReviewState:\n",
    "    \"\"\"Pause execution before AI review for human input.\"\"\"\n",
    "    print(\"\\n Execution Paused! Human Review Needed.\")\n",
    "    human_decision = input(\"Enter decision (Approve/Reject/Continue to AI): \").strip().lower()\n",
    "\n",
    "    if human_decision in [\"approve\", \"reject\"]:\n",
    "        return {\"status\": human_decision, \"request_data\": state[\"request_data\"]}  # Skip AI\n",
    "    else:\n",
    "        return state  # Continue to AI Review\n",
    "\n",
    "# Step 8: Compile Workflow with `interrupt_before`\n",
    "app = workflow.compile()\n",
    "\n",
    "# Step 9: Execute Streaming with `app.stream()`\n",
    "print(\"\\n🚀 Streaming Execution Started...\\n\")\n",
    "\n",
    "# # Run the streaming process in a separate thread\n",
    "# thread = threading.Thread(target=lambda: app.stream({\"request_data\": \"Developer wants to add a new feature\"}))\n",
    "# thread.start()\n",
    "\n",
    "#Process streaming output (Fixed Issue)\n",
    "for event in app.stream({\"request_data\": \"Developer wants to add a new feature\"}):\n",
    "    if isinstance(event, dict) and \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "print(\"\\n✅ Final Decision Reached!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string expression part cannot include a backslash (2302756397.py, line 63)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m{'It must be tailored as much as possible to the prospect\\'s company based on the website information we fetched. Don\\'t mention that we got the information from the website. Include no placeholders! Your response should be nothing but the pure email body!' if not no_domain else ''}\"\"\"),\u001b[39m\n                                                                                                                                                                                                                                                                                                  ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m f-string expression part cannot include a backslash\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import re\n",
    "import os\n",
    "from typing import Optional, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from fastapi import FastAPI, Request\n",
    "from gotohuman import GotoHuman\n",
    "from firecrawl import FirecrawlApp\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Command, interrupt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "app = FastAPI()\n",
    "gotohuman = GotoHuman()\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    email_address: str\n",
    "    lead_website_url: str\n",
    "    email_to_send: str\n",
    "\n",
    "@tool\n",
    "async def web_scrape_tool(url: str) -> str:\n",
    "    \"\"\"Scrape a website\"\"\"\n",
    "    app = FirecrawlApp(api_key=os.getenv(\"FIRECRAWL_API_KEY\"))\n",
    "    scrape_result = app.scrape_url(url, params={'formats': ['markdown']})\n",
    "    print(f\"Scraped website {url}: {scrape_result['markdown'][:50]}\")\n",
    "    return scrape_result[\"markdown\"]\n",
    "\n",
    "@tool\n",
    "async def summarizer_tool(content: str) -> str:\n",
    "    \"\"\"Summarize scraped website content\"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a helpful website content summarizer. You will be passed the content of a scraped company website. Please summarize it in 250-300 words focusing on what kind of company this is, the services they offer and how they operate.\"),\n",
    "        HumanMessage(content=content),\n",
    "    ]\n",
    "    model = ChatOpenAI(temperature=0.5, model=\"gpt-4o-mini\")\n",
    "    response = await model.ainvoke(messages)\n",
    "    print(f\"Summarized website: {response.content[:100]}\")\n",
    "    return response.content\n",
    "\n",
    "@tool\n",
    "async def draft_tool(email_address: str, company_description: str, previous_draft: Optional[str], retry_comment: Optional[str]) -> str:\n",
    "    \"\"\"Write or revise a sales email.\"\"\"\n",
    "    no_domain = not bool(company_description)\n",
    "    \n",
    "    sender_name = \"Jess\"\n",
    "    sender_company_desc = \"FreshFruits is a premier subscription-based delivery service...\"\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=f\"\"\"You are a helpful sales expert, great at writing enticing emails.\n",
    "        You will write an email for {sender_name} who wants to reach out to a new prospect who left their email address: {email_address}. {sender_name} works for the following company:\n",
    "        {sender_company_desc}\n",
    "        Write no more than 300 words.\n",
    "        {'It must be tailored as much as possible to the prospect\\'s company based on the website information we fetched. Don\\'t mention that we got the information from the website. Include no placeholders! Your response should be nothing but the pure email body!' if not no_domain else ''}\"\"\"),\n",
    "        HumanMessage(content=\"No additional information found about the prospect\" if no_domain else f\"#Company website summary:\\n{company_description}\")\n",
    "    ]\n",
    "    if previous_draft:\n",
    "        messages.append(AIMessage(content=previous_draft))\n",
    "    if retry_comment:\n",
    "        messages.append(HumanMessage(content=retry_comment))\n",
    "    \n",
    "    model = ChatOpenAI(temperature=0.75, model=\"gpt-4o-mini\")\n",
    "    response = await model.ainvoke(messages)\n",
    "    print(f\"Drafted email: {response.content[:100]}\")\n",
    "    return response.content\n",
    "\n",
    "def extract_domain(state: State):\n",
    "    email_address = state[\"email_address\"]\n",
    "    common_providers = [\n",
    "        'gmail', 'yahoo', 'ymail', 'rocketmail',\n",
    "        'outlook', 'hotmail', 'live', 'msn',\n",
    "        'icloud', 'me', 'mac', 'aol',\n",
    "        'zoho', 'protonmail', 'mail', 'gmx'\n",
    "    ]\n",
    "    \n",
    "    url = None\n",
    "    domain = email_address.split('@')[-1] if '@' in email_address else None\n",
    "    if domain:\n",
    "        pattern = fr\"^({'|'.join(common_providers)})\\.(?:com|net|org|edu|.*)\"\n",
    "        if not re.search(pattern, domain):\n",
    "            url = f\"https://{domain}\"\n",
    "    print(f\"Extracted domain from email address {email_address}: {url}\")\n",
    "    return {\"lead_website_url\": url, \"messages\": [HumanMessage(content=f\"We got the email address of a new lead: {state['email_address']}. {f'Scrape the corresponding website: {url}. Then use the summarizer tool to describe it.' if url else ''} Then write an outreach email. Only respond with the email body!\")]}\n",
    "\n",
    "tools = [web_scrape_tool, summarizer_tool, draft_tool]\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "def route_tools(\n",
    "    state: State,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the human approval.\n",
    "    \"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return \"ask_human\"\n",
    "\n",
    "def human_approval(\n",
    "        state: State,\n",
    "):\n",
    "    # Get the last ToolMessage with name \"draft_tool\" which is the drafted email\n",
    "    messages = state.get(\"messages\", [])\n",
    "    draft_tool_message = next((msg for msg in reversed(messages) if isinstance(msg, AIMessage)), None)\n",
    "    if not draft_tool_message:\n",
    "        raise ValueError(f\"No ToolMessage with name 'draft_tool' found: {state}\")\n",
    "    email_draft_content = draft_tool_message.content\n",
    "    \n",
    "    # The interrupt will surface the email draft to our graph run. The returned interrupt will continue here with the response from gotoHuman.\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"email_draft\": email_draft_content,\n",
    "        },\n",
    "    )\n",
    "    print(f\"Interrupt returned human response: {human_response}\")\n",
    "    response = human_response.get(\"response\", \"\")\n",
    "    emailContentReviewed = human_response.get(\"reviewed_email\", \"\")\n",
    "    retryComment = human_response.get(\"comment\", \"\")\n",
    "\n",
    "    if response == \"retry\":\n",
    "        return Command(goto=\"agent\", update={\"messages\": [HumanMessage(content=f\"Please revise the previous draft considering the following: {retryComment}.\\nAgain, only respond with the email body!\")]})\n",
    "    elif response == \"approve\":\n",
    "        return Command(goto=\"send_email\", update={\"email_to_send\": emailContentReviewed})\n",
    "    return Command(goto=END)\n",
    "    \n",
    "    \n",
    "def send_email(\n",
    "    state: State,\n",
    "):\n",
    "    email_address = state.get(\"email_address\")\n",
    "    email = state.get(\"email_to_send\")\n",
    "    print(f\"Sending email to {email_address} with content: {email[:50]}\")\n",
    "    # TODO: Implement sending email\n",
    "    return {\"messages\": [AIMessage(content=f\"Email sent to {email_address}\")]}\n",
    "\n",
    "@app.post(\"/\")\n",
    "async def process_request(request: Request):\n",
    "    req = await request.json()\n",
    "    thread_id = req.get(\"meta\", {}).get(\"threadId\") or str(uuid.uuid4())\n",
    "\n",
    "    graph_builder = StateGraph(State)\n",
    "    graph_builder.add_node(\"extract_domain\", extract_domain)\n",
    "    graph_builder.add_node(\"agent\", chatbot)\n",
    "\n",
    "    tool_node = ToolNode(tools=tools)\n",
    "    graph_builder.add_node(\"tools\", tool_node)\n",
    "    graph_builder.add_node(\"ask_human\", human_approval, destinations=(\"agent\", \"send_email\", END))\n",
    "    graph_builder.add_node(\"send_email\", send_email)\n",
    "\n",
    "    graph_builder.add_edge(START, \"extract_domain\")\n",
    "    graph_builder.add_edge(\"extract_domain\", \"agent\")\n",
    "    graph_builder.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        route_tools,\n",
    "    )\n",
    "    graph_builder.add_edge(\"tools\", \"agent\")\n",
    "    graph_builder.add_edge(\"send_email\", END)\n",
    "\n",
    "    # Initialize DB to persist state of the conversation thread between graph runs\n",
    "    async with AsyncPostgresSaver.from_conn_string(os.getenv(\"POSTGRES_CONN_STRING\")) as memory:\n",
    "        #check if no threadId is provided\n",
    "        if req.get(\"meta\", {}).get(\"threadId\") is None:\n",
    "          await memory.setup()\n",
    "        graph = graph_builder.compile(checkpointer=memory)\n",
    "        thread_config = { \"configurable\": { \"thread_id\": thread_id } }\n",
    "            \n",
    "        if req.get(\"type\") == \"trigger\" or req.get(\"email\"):\n",
    "            # we were called by the gotoHuman trigger or by another triggering request including an email\n",
    "            email_address = req.get(\"email\") or req.get(\"responseValues\", {}).get(\"email\", {}).get(\"value\", \"\")\n",
    "            print(f\"Starting graph with email address: {email_address}\")\n",
    "            await graph.ainvoke({\"email_address\": email_address}, config=thread_config)\n",
    "        \n",
    "        elif req.get(\"type\") == \"review\":\n",
    "            # we were called again with the review response from gotoHuman\n",
    "            approval = req[\"responseValues\"].get(\"emailApproval\", {}).get(\"value\", \"\")\n",
    "            email_text = req[\"responseValues\"].get(\"emailDraft\", {}).get(\"value\", \"\")\n",
    "            retry_comment = req[\"responseValues\"].get(\"retryComment\", {}).get(\"value\", \"\")\n",
    "            \n",
    "            await graph.ainvoke(Command(resume={ \"response\": approval, \"reviewed_email\": email_text, \"comment\": retry_comment }), config=thread_config)\n",
    "\n",
    "        # check if the graph reached the interrupt in node \"ask_human\"\n",
    "        state = await graph.aget_state(thread_config)\n",
    "        if state.tasks and state.tasks[0].name == \"ask_human\":\n",
    "            email_draft = state.tasks[0].interrupts[0].value[\"email_draft\"] if state.tasks else None\n",
    "            email_address = state.values.get(\"email_address\", \"\")\n",
    "            website_url = state.values.get(\"lead_website_url\", \"\")\n",
    "            \n",
    "            # Create review request with GotoHuman\n",
    "            review_request = (\n",
    "                gotohuman.create_review(os.getenv(\"GOTOHUMAN_FORM_ID\"))\n",
    "                .add_field_data(\"email\", email_address)\n",
    "                .add_field_data(\"emailDomain\", {\"url\": website_url, \"label\": \"Website checked\"})\n",
    "                .add_field_data(\"emailDraft\", email_draft)\n",
    "                .add_meta_data(\"threadId\", thread_id)\n",
    "            )\n",
    "            \n",
    "            gotohuman_response = await review_request.async_send_request()\n",
    "            print(f\"gotoHuman: requested human review: {gotohuman_response}\")\n",
    "            return {\"message\": \"The email draft needs human review.\", \"link\": gotohuman_response[\"gthLink\"]}\n",
    "    \n",
    "    print(\"Graph ended\")\n",
    "    return {\"message\": \"Graph ended\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
